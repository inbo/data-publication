---
title: "Darwin Core mapping"
subtitle: "For: kevers checklist"
author:
- author_1
- author_2
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
#  pdf_document:
#    df_print: kable
#    number_sections: yes
#    toc: yes
#    toc_depth: 3
---

# Setup 

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = TRUE)
```

Install required libraries (only if the libraries have not been installed before):

```{r eval=FALSE, include=FALSE}
installed <- rownames(installed.packages())
required <- c("tidyverse", "tidylog", "magrittr", "here", "janitor", "readxl", "digest", "rgbif")
if (!all(required %in% installed)) {
  install.packages(required[!required %in% installed])
}
```

Load libraries:

```{r message = FALSE}
library(tidyverse)      # To do data science
library(tidylog)        # To provide feedback on dplyr functions
library(magrittr)       # To use %<>% pipes
library(here)           # To find files
library(janitor)        # To clean input data
library(readxl)         # To read Excel files
library(digest)         # To generate hashes
library(rgbif)          # To use GBIF services
library(fuzzyjoin)
library(stringdist)
```

# Read source data

Create a data frame `input_data` from the source data:

```{r}
input_data <- read_excel(path = here("datasets","checklist-kevers","data", "raw", "Checklist_coleoptera_update.xlsx")) 
```

```{r}
reference_data <- read_excel(path = here("datasets","checklist-kevers","data", "raw", "referenties2025_GBIF_ok.xlsx")) 
```



Preview data:

```{r}
input_data %>% head(n = 5)
```

# Process source data

## Tidy data

Clean data somewhat:

```{r}
input_data %<>% remove_empty("rows")
```

```{r}
input_data %<>% clean_names()
```

# better solution tahn paste(genus, ... ), deals with the NA's in subspecies

```{r}
input_data %<>%
  unite("scientificName", genus, species, subspecies, species_auctor,
        sep = " ", na.rm = TRUE, remove = FALSE)
```


```{r}
input_data %<>% mutate(kingdom = 'animalia')
```


```{r}
duplicates <- input_data %>%
  group_by(scientificName) %>%
  filter(n() > 1) %>%
  arrange(scientificName)
```



## Scientific names

Use the [GBIF nameparser](https://www.gbif.org/tools/name-parser) to retrieve nomenclatural information for the scientific names in the checklist:

```{r}
parsed_names <- input_data %>%
  distinct(scientificName) %>%
  pull() %>% # Create vector from dataframe
  parsenames() # An rgbif function
```

Show scientific names with nomenclatural issues, i.e. not of `type = SCIENTIFIC` or that could not be fully parsed. Note: these are not necessarily incorrect.

```{r}
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE"))
```

```{r}
parsed_names2 <- parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "TRUE"))
```

Correct names and reparse:

```{r correct and reparse, eval=FALSE, include=FALSE}
input_data %<>% mutate(scientific_name = recode(scientific_name,
  "Asero√ô rubra" = "Asero rubra"
))
# Redo parsing
parsed_names <- input_data %>%
  distinct(scientific_name) %>%
  pull() %>%
  parsenames()
# Show names with nomenclatural issues again
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE"))
```

## Taxon ranks

The nameparser function also provides information about the rank of the taxon (in `rankmarker`). Here we join this information with our checklist. Cleaning these ranks will done in the Taxon Core mapping:

```{r}
input_data %<>% left_join(
  parsed_names %>%
  select(scientificname, rankmarker),
  by = c("scientificName" = "scientificname"))
```






## Taxon IDs

To link taxa with information in the extension(s), each taxon needs a unique and relatively stable `taxonID`. Here we create one in the form of `dataset_shortname:taxon:hash`, where `hash` is unique code based on scientific name and kingdom (that will remain the same as long as scientific name and kingdom remain the same):

```{r}
vdigest <- Vectorize(digest) # Vectorize digest function to work with vectors
input_data %<>% mutate(taxon_id = paste(
  "checklist_coleoptera", # e.g. "alien-fishes-checklist"
  "taxon",
  vdigest(paste(scientificName, kingdom), algo = "md5"),
  sep = ":"
))
```


```{r}
Duplicates_taxonID <- input_data %>%
  group_by(taxon_id) %>%
  filter(n() > 1) %>%
  arrange(taxon_id)
```
## Preview data

Show the number of taxa and distributions per kingdom and rank:

```{r}
input_data %>%
  group_by(kingdom, rankmarker) %>%
  summarize(
    `# taxa` = n_distinct(taxon_id),
    `# distributions` = n()
  ) %>%
  adorn_totals("row")
```

Preview data:

```{r}
input_data %>% head()
```

# Taxon core

```{r}

duplicates <- input_data[duplicated(input_data), ]
```

```{r}
duplicates <- input_data %>%
  group_by(across(everything())) %>%
  filter(n() > 1)
```


## Pre-processing

Create a dataframe with unique taxa only (ignoring multiple distribution rows):

```{r}
taxon <- input_data %>% distinct(taxon_id, .keep_all = TRUE)

```
# show duplicate rows (the ones removed by distinct)

```{r}

duplicates <- input_data[duplicated(input_data), ]
```



## Term mapping

Map the data to [Darwin Core Taxon](http://rs.gbif.org/core/dwc_taxon_2015-04-24.xml).

Start with record-level terms which contain metadata about the dataset (which is generally the same for all records).

### language

```{r}
taxon %<>% mutate(dwc_language = "en") # e.g. "en"
```

### license

```{r}
taxon %<>% mutate(dwc_license = "http://creativecommons.org/publicdomain/zero/1.0/") # e.g. "http://creativecommons.org/publicdomain/zero/1.0/"
```

### rightsHolder

```{r}
taxon %<>% mutate(dwc_rightsHolder = "INBO") # e.g. "INBO"
```

### datasetID

```{r}
taxon %<>% mutate(dwc_datasetID = "my_dataset_doi") # e.g. "https://doi.org/10.15468/xvuzfh"
```

### institutionCode

```{r}
taxon %<>% mutate(dwc_institutionCode = "INBO") # e.g. "INBO"
```

### datasetName

```{r}
taxon %<>% mutate(dwc_datasetName = "Checklist of Coleoptera in Belgium") # e.g. "Checklist of non-native freshwater fishes in Flanders, Belgium"
```

The following terms contain information about the taxon:

### taxonID

```{r}
taxon %<>% mutate(dwc_taxonID = taxon_id)
```

```{r}
taxon %<>% mutate(
  dwc_establishmentMeans = case_when(
    is.na(non_native)          ~ "native",        # true NA (missing value)
    non_native == "NA"         ~ "not applied",   # literal string "NA"
    non_native == "N"          ~ "non native",    # code for non-native
    non_native == "Non-native" ~ "non native", 
    TRUE                     ~ ""               # default (optional)
  )
)
```






### scientificName

```{r}
taxon %<>% mutate(dwc_scientificName = scientificName)
```



```{r}
taxon %<>% mutate(dwc_scientificNameAuthorship = species_auctor)
```




### kingdom

Inspect values:

```{r}
taxon %>%
  group_by(kingdom) %>%
  count()
```

Map values:

```{r}
taxon %<>% mutate(dwc_kingdom = kingdom)
```



```{r}
taxon %<>% mutate(dwc_genus = genus)
```
```{r}
taxon %<>% mutate(dwc_family = family)
```



```{r}
taxon %<>% mutate(dwc_subfamily = subfamily)
```

```{r}
taxon %<>% mutate(dwc_infraspecificEpithet = subspecies)
```


### taxonRank

Inspect values:

```{r}
taxon %>%
  group_by(rankmarker) %>%
  count()
```

Map values by recoding to the [GBIF rank vocabulary](http://rs.gbif.org/vocabulary/gbif/rank_2015-04-24.xml):

```{r}
taxon %<>% mutate(dwc_taxonRank = recode(rankmarker,
  "agg."      = "speciesAggregate",
  "infrasp."  = "infraspecificname",
  "sp."       = "species",
  "var."      = "variety",
  .default    = "",
  .missing    = ""
))
```

Inspect mapped values: 

```{r}
taxon %>%
  group_by(rankmarker, dwc_taxonRank) %>%
  count()
```

### nomenclaturalCode

```{r}
taxon %<>% mutate(dwc_nomenclaturalCode = "ICZN") # e.g. "ICZN"
```

## Post-processing

Only keep the Darwin Core columns:

```{r}
taxon %<>% select(starts_with("dwc_"))
```

Drop the `dwc_` prefix:

```{r}
colnames(taxon) <- str_remove(colnames(taxon), "dwc_")
```

Preview data:

```{r}
taxon %>% head()
```

Save to CSV:

```{r}
write_csv(taxon, here("datasets","checklist-kevers","data", "processed", "taxon.csv"), na = "")
```

# Distribution extension

## Pre-processing

Create a dataframe with all data:

```{r}
distribution <- input_data
```

## Term mapping

Map the data to [Species Distribution](http://rs.gbif.org/extension/gbif/1.0/distribution.xml).

### taxonID

```{r}
distribution %<>% mutate(dwc_taxonID = taxon_id)
```
### remarks occurrence

```{r}
distribution %<>% mutate(dwc_occurrenceRemarks = remarks)
```
```{r}
distribution %<>% mutate(
  dwc_establishmentMeans = case_when(
    is.na(non_native)          ~ "native",        # true NA (missing value)
    non_native == "NA"         ~ "not applied",   # literal string "NA"
    non_native == "N"          ~ "non native",    # code for non-native
    non_native == "Non-native" ~ "non native", 
    TRUE                     ~ ""               # default (optional)
  )
)
```

### locality

```{r}
distribution %<>% mutate(dwc_countryCode = "BE")
```

```{r}
distribution <- distribution %>%
  pivot_longer(
    cols = c(bel, vla, bru, wal),
    names_to = "dwc_stateProvince",
    values_to = "dwc_eventDate"
  ) %>%
  filter(!is.na(year))  # optioneel: NA-records wegfilteren
```




Inspect values:





Map values to `locality` if provided, otherwise use the country name:

```{r}
distribution %<>% mutate(dwc_locality = case_when(
  !is.na(dwc_countryCode) ~ dwc_countryCode,
  dwc_countryCode == "BE" ~ "Belgium",
  dwc_countryCode == "GB" ~ "United Kingdom",
  dwc_countryCode == "MK" ~ "Macedonia",
  dwc_countryCode == "NL" ~ "The Netherlands",
  TRUE ~ "" # In other cases leave empty
))
```

```{r}
distribution %>%
  group_by(dwc_countryCode, dwc_locality) %>%
  count()
```

Inspect mapped values: 



### countryCode


### occurrenceStatus

Inspect values:


Map values:

```{r}
distribution %<>% mutate(dwc_occurrenceStatus = case_when(
              !is.na(dwc_eventDate) ~ "present",
              is.na(dwc_eventDate) ~ "absent" ))
```

### source



```{r}
distribution %<>% mutate(dwc_source = coalesce(previous_checklist_used, reference, additional_new_reference, family_subfamily_reference) )
```
### split in 3 distribution files BE-wal-VL


```{r}
distribution %<>% mutate(dwc_stateProvince = case_when(
    dwc_stateProvince == "bel" ~ "Belgium",
    dwc_stateProvince == "vla" ~ "Flanders",
    dwc_stateProvince == "wal" ~ "Wallonia",
    dwc_stateProvince == "bru" ~ "Brussels",
    TRUE ~ NA_character_
  ))
```

```{r}
distribution_flanders <- distribution %>% 
  filter(dwc_stateProvince == "Flanders")

```
```{r}


distribution_wallonia <- distribution %>% 
  filter(dwc_stateProvince == "Wallonia")

distribution_brussels <- distribution %>% 
  filter(dwc_stateProvince == "Brussels")

distribution_belgium <- distribution %>% 
  filter(dwc_stateProvince == "Belgium")

```


## Post-processing

Only keep the Darwin Core columns:

```{r}
distribution_belgium %<>% select(starts_with("dwc_"))

distribution_flanders %<>% select(starts_with("dwc_"))

distribution_brussels %<>% select(starts_with("dwc_"))

distribution_wallonia %<>% select(starts_with("dwc_"))
```

Drop the `dwc_` prefix:

```{r}
colnames(distribution_belgium) <- str_remove(colnames(distribution_belgium), "dwc_")

colnames(distribution_flanders) <- str_remove(colnames(distribution_flanders), "dwc_")

colnames(distribution_brussels) <- str_remove(colnames(distribution_brussels), "dwc_")

colnames(distribution_wallonia) <- str_remove(colnames(distribution_wallonia), "dwc_")
```

Preview data:


```{r}
distribution_flanders %>% head()
```

```{r}
distribution_belgium %>% head()
```

Save to CSV:

```{r}
write_csv(distribution_flanders, here("datasets" ,"checklist-kevers", "data", "processed", "distribution_flanders.csv"), na = "")
```

```{r}
write_csv(distribution_belgium, here("datasets" ,"checklist-kevers", "data", "processed", "distribution_belgium.csv"), na = "")
```

```{r}
write_csv(distribution_wallonia, here("datasets" ,"checklist-kevers", "data", "processed", "distribution_wallonia.csv"), na = "")
```

```{r}
write_csv(distribution_brussels, here("datasets" ,"checklist-kevers", "data", "processed", "distribution_brussels.csv"), na = "")
```



### references

```{r}
references <- input_data %>% distinct(taxon_id, .keep_all = TRUE)

```
```{r}
references %<>% mutate(dwc_source = coalesce(previous_checklist_used, reference, additional_new_reference, family_subfamily_reference, "unknown") )
```

## fuzzy join reference_data

```{r}
references$dwc_source <- as.character(references$dwc_source)
reference_data$ScienticAuthorship <- as.character(reference_data$ScienticAuthorship)
```

```{r}
references <- references %>%
  mutate(
    match_input = coalesce(dwc_source, reference, "Unknown")
  )
```
```{r}
dist_mat <- stringdistmatrix(
  a = references$match_input,
  b = reference_data$ScientificAuthorship,
  method = "osa"   # Optimal String Alignment
)
```

```{r}
best_match_idx <- apply(dist_mat, 1, which.min)
best_dist <- apply(dist_mat, 1, min)
```


```{r}
references_matched <- references %>%
  mutate(
    matched_reference = reference_data$ScientificAuthorship[best_match_idx],
    match_distance = best_dist
  )
```


```{r}
references_matched <- stringdist_left_join(
  references,          # linker dataframe: alles behouden
  reference_data,      # rechter dataframe: fuzzy match tegen deze kolom
  by = c("dwc_source" = "ScientificAuthorship"),
  max_dist = 2,        # maximale fuzzy afstand
  distance_col = "dist"
)
```



```{r}

references_match <- references %>%
  stringdist_left_join(reference_data,
                       by = c("ScienticAuthorship" = "dwc_source" ),
                       max_dist = 2,          # pas aan: hoe tolerant wil je zijn?
                       distance_col = "dist") %>%
  select(-col) %>%
  group_by(ScienticAuthorship) %>%
  slice_min(dist, n = 1) %>%   # kies de beste match per record
  ungroup()

```

```{r}
test <- fuzzyjoin::stringdist_inner_join(
  references,
  reference_data,
  by = c("ScientificAuthorship" = "dwc_source"),
  max_dist = 2,
  distance_col = "dist"
)
```


